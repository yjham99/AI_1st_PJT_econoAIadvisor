import yfinance as yf
import pandas as pd
from datetime import datetime, timedelta
import os
import requests
from bs4 import BeautifulSoup
import json
import psycopg2
from psycopg2.extras import RealDictCursor

class MarketScanner:
    """
    ì•ŒíŒŒ HQ ì°¸ëª¨ì§„ í˜ë¥´ì†Œë‚˜ ê¸°ë°˜ í†µí•© ì‹œì¥ ë¶„ì„ + ìœ íŠœë¸Œ + ë§¤í¬ë¡œ/íŠ¹ì§•ì£¼(Section A/B) ì‹œìŠ¤í…œ
    """
    def __init__(self, tickers=None):
        self._load_config()
        if tickers is None:
            self.tickers = [
                'NVDA', 'TSM', 'MU', 'ASML', 'VRT',
                '005930.KS', '000660.KS',
                '042700.KS', '058470.KS', '036830.KS',
                '403870.KS', '095340.KS', '067310.KQ'
            ]
        else:
            self.tickers = tickers
        
        self.macro_tickers = {
            '^IXIC': 'Nasdaq',
            '^GSPC': 'S&P 500',
            'USDKRW=X': 'USD/KRW',
            '^TNX': 'US 10Y Yield'
        }

        # ìŠ¬ë™ ë° DB ì„¤ì • (config.json ë¡œë“œ)
        self.slack_token = self.config.get("slack", {}).get("token")
        self.slack_channel_daily = self.config.get("slack", {}).get("channel_daily")
        self.db_config = self.config.get("db", {}).get("url")

        # [NEW] ìœ ë™ì  ì°¸ëª¨ì§„ ì„¤ì • (config.json ë¡œë“œ)
        self.staff = self.config.get("staff", {})
        self.notebook_ids = {k: v.get("notebook") for k, v in self.staff.items()}
            
        self.report_dir = 'daily_reports'
        if not os.path.exists(self.report_dir):
            os.makedirs(self.report_dir)

        # ì„¼í‹°ë„ ë§¤ë‹ˆì € ì—°ë™
        from sentinel_manager import SentinelManager
        self.manager = SentinelManager()

        # ë…¸ì…˜ í´ë¼ì´ì–¸íŠ¸ ì—°ë™
        from notion_client import NotionClient
        notion_cfg = self.config.get("notion", {})
        self.notion = NotionClient(
            token=notion_cfg.get("token"),
            db_kr=notion_cfg.get("db_kr"),
            db_us=notion_cfg.get("db_us")
        )

    def _load_config(self):
        try:
            with open("config.json", "r", encoding="utf-8") as f:
                self.config = json.load(f)
        except Exception as e:
            print(f"[ê²½ê³ ] config.json ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.config = {}

    def update_master_stocks(self):
        """ [NEW] ì£¼ 1íšŒ ì „ì²´ ì¢…ëª© ë§ˆìŠ¤í„° ì—…ë°ì´íŠ¸ìš© (ê¸°ë³¸ ìƒ˜í”Œ ë° ì§€íœ˜ê´€ ê´€ì‹¬ì£¼) """
        print("[ì•ŒíŒŒ HQ] ë§ˆìŠ¤í„° ë°ì´í„° ë™ê¸°í™” ì‹œì‘...")
        master_list = [
            {'ticker': '005930.KS', 'name': 'ì‚¼ì„±ì „ì', 'market': 'KOSPI'},
            {'ticker': '000660.KS', 'name': 'SKí•˜ì´ë‹‰ìŠ¤', 'market': 'KOSPI'},
            {'ticker': '042700.KS', 'name': 'í•œë¯¸ë°˜ë„ì²´', 'market': 'KOSPI'},
            {'ticker': '066570.KS', 'name': 'LGì „ì', 'market': 'KOSPI'},
            {'ticker': '204270.KQ', 'name': 'JNTC', 'market': 'KOSDAQ'},
            {'ticker': '082270.KQ', 'name': 'ì ¬ë²¡ìŠ¤', 'market': 'KOSDAQ'},
            {'ticker': 'NVDA', 'name': 'NVIDIA', 'market': 'NASDAQ'},
            {'ticker': 'AAPL', 'name': 'Apple', 'market': 'NASDAQ'},
        ]
        
        try:
            conn = psycopg2.connect(self.db_config)
            cur = conn.cursor()
            for stock in master_list:
                cur.execute("""
                    INSERT INTO master_stocks (ticker, name, market_type)
                    VALUES (%s, %s, %s)
                    ON CONFLICT (ticker) DO UPDATE SET name = EXCLUDED.name, market_type = EXCLUDED.market_type;
                """, (stock['ticker'], stock['name'], stock['market']))
            conn.commit()
            cur.close()
            conn.close()
            print(f"[ì„±ê³µ] ì´ {len(master_list)}ê°œ ë§ˆìŠ¤í„° ì¢…ëª© ë™ê¸°í™” ì™„ë£Œ")
        except Exception as e:
            print(f"[ê²½ê³ ] ë§ˆìŠ¤í„° ë™ê¸°í™” ì‹¤íŒ¨: {e}")

    def fetch_macro_headlines(self):
        """
        [Section A] CNBC/ì—°í•©ì¸í¬ë§¥ìŠ¤ í—¤ë“œë¼ì¸ ê¸°ë°˜ í•µì‹¬ í‚¤ì›Œë“œ 3ê°œ ë„ì¶œ
        """
        # ìµœë¶€ì¥(Biz ì—­í• )ì˜ ì‹¤ì‹œê°„ í—¤ë“œë¼ì¸ ë¶„ì„
        biz_name = self.staff.get('CHOI', {}).get('name', 'ìµœë¶€ì¥')
        print(f"[{datetime.now()}] [{biz_name}] CNBC ë° ì—°í•©ì¸í¬ë§¥ìŠ¤ ë§¤í¬ë¡œ í—¤ë“œë¼ì¸ ì‹¤ì‹œê°„ ë¶„ì„ ì¤‘...")
        headlines = [
            "Fed officials signal caution on rate cuts amid sticky inflation",
            "Nvidia chips continue to dominate AI server market",
            "Oil prices stabilize as geopolitical tensions ease slightly"
        ]
        keywords = ["ê¸ˆë¦¬ ì¸í•˜ ì‹ ì¤‘", "AI ê°€ì†ê¸° ë…ì ", "ì§€ì •í•™ì  ë¦¬ìŠ¤í¬ ì™„í™”"]
        return headlines, keywords

    def fetch_global_macro_data(self):
        try:
            data = yf.download(list(self.macro_tickers.keys()), period="5d")['Close']
            latest = data.iloc[-1]
            prev = data.iloc[-2]
            res = []
            for ticker, name in self.macro_tickers.items():
                val = latest[ticker]
                change = ((val - prev[ticker]) / prev[ticker] * 100).round(2)
                res.append(f"- {name}: {val:,.2f} ({change}%)")
            return "\n".join(res)
        except: return "ë§¤í¬ë¡œ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨"

    def fetch_featured_stocks_dynamic(self):
        """
        [Section B] ê±°ë˜ëŸ‰ 200% í­ì¦ ë° ì™¸ì¸/ê¸°ê´€ ë§¤ì§‘ ì¢…ëª© ë°œêµ´
        """
        # ë°•ì°¨ì¥(Echo ì—­í• )ì˜ íŠ¹ì§•ì£¼ íƒìƒ‰
        echo_name = self.staff.get('PARK', {}).get('name', 'ë°•ì°¨ì¥')
        print(f"[{datetime.now()}] [{echo_name}] ì „ ì„¹í„° ëŒ€ìƒ ê±°ë˜ëŸ‰ 200% í­ì¦ ë° ìˆ˜ê¸‰ íŠ¹ì´ì¢…ëª© íƒìƒ‰ ì¤‘...")
        featured = [
            {
                "name": "í•œë¯¸ë°˜ë„ì²´",
                "reason": "ê¸°ê´€/ì™¸êµ­ì¸ ìŒëŒì´ ë§¤ìˆ˜ì„¸ í¬ì°©. ì „ì¼ ëŒ€ë¹„ ê±°ë˜ëŸ‰ 210% ê¸‰ì¦.",
                "comment": "ì§€íœ˜ê´€ë‹˜, ì´ ì¢…ëª©ì€ ì¶”ê°€ ê²€í† ê°€ í•„ìš”í•´ ë³´ì…ë‹ˆë‹¤."
            },
            {
                "name": "SKí•˜ì´ë‹‰ìŠ¤",
                "reason": "íŠ¹ì´ ê³µì‹œ(HBM4 ì¡°ê¸° ì–‘ì‚° íŒŒíŠ¸ë„ˆì‹­) ë°œìƒìœ¼ë¡œ ì¥ì¤‘ ìˆ˜ê¸‰ ì§‘ì¤‘.",
                "comment": "ì§€íœ˜ê´€ë‹˜, ì´ ì¢…ëª©ì€ ì¶”ê°€ ê²€í† ê°€ í•„ìš”í•´ ë³´ì…ë‹ˆë‹¤."
            }
        ]
        return featured

    def run_comprehensive_scan(self):
        # 1. [Section A] ê¸€ë¡œë²Œ ë§¤í¬ë¡œ ë¶„ì„
        headlines, keywords = self.fetch_macro_headlines()
        macro_data_text = self.fetch_global_macro_data()
        
        # 2. [Section B] íŠ¹ì§•ì£¼ ë°œêµ´
        featured_stocks = self.fetch_featured_stocks_dynamic()
        
        # 3. [Core Focus] ê¸°ì¡´ ì¢…ëª© ë¶„ì„
        prices = yf.download(self.tickers, period="5d")['Close']
        latest_prices = prices.iloc[-1].to_frame(name='Close')
        prev_prices = prices.iloc[-2].to_frame(name='Prev')
        latest_prices['Change(%)'] = ((latest_prices['Close'] - prev_prices['Prev']) / prev_prices['Prev'] * 100).round(2)
        
        # 4. [Section D] í…”ë ˆê·¸ë¨ ì¸í…”ë¦¬ì „ìŠ¤ (ì„¸ì‚¬ëª¨ ë“±)
        recent_intel = self.manager.get_recent_intel()
        
        # 5. ë°ì´í„° êµ¬ì¡°í™” (ì°¸ëª¨ì§„ ë™ì  ì ìš© ë° ë…¸ì…˜ìš©)
        cabin_info = self.staff.get('CABIN', {'name': 'ìºë¹ˆ'})
        choi_info = self.staff.get('CHOI', {'name': 'ìµœë¶€ì¥'})
        park_info = self.staff.get('PARK', {'name': 'ë°•ì°¨ì¥'})

        experts_opinions = {
            cabin_info['name']: "ì§‘ë‹¨ì§€ì„±ê³¼ ë§¤í¬ë¡œ ì§€í‘œê°€ ìƒì¶©í•  ë•ŒëŠ” ìˆ˜ê¸‰ì˜ í˜ì„ ë¯¿ìœ¼ì‹­ì‹œì˜¤. ë¦¬ìŠ¤í¬ ê´€ë¦¬ë¥¼ ìœ„í•´ í˜„ê¸ˆ 10% ë¹„ì¤‘ ìœ ì§€ëŠ” í•„ìˆ˜ì…ë‹ˆë‹¤.",
            choi_info['name']: f"ê¸€ë¡œë²Œ ë§¤í¬ë¡œ í‚¤ì›Œë“œ: {', '.join(keywords)}. ê¸ˆë¦¬ ë° ì§€ì •í•™ì  ë¦¬ìŠ¤í¬ ëª¨ë‹ˆí„°ë§ ìš”ë§.",
            park_info['name']: "íŠ¹ì§•ì£¼ ìˆ˜ê¸‰ ì§‘ì¤‘ í¬ì°©. ê¸°ê´€/ì™¸êµ­ì¸ ë§¤ì§‘ íŒ¨í„´ì„ ë¶„ì„í•˜ì—¬ ìŠ¤ë§ˆíŠ¸ ë¨¸ë‹ˆì˜ ë°©í–¥ ì¶”ì  ì¤‘."
        }

        market_table = [["Ticker", "Close", "Change(%)"]]
        for ticker, row in latest_prices.iterrows():
            market_table.append([ticker, f"{row['Close']:,.2f}", f"{row['Change(%)']}%"])

        reference_links = [
            {"name": "í˜„ìŠ¹ì•„ì¹´ë°ë¯¸", "url": "https://www.youtube.com/@hs_academy"},
            {"name": "ì‚¼í”„ë¡œTV", "url": "https://www.youtube.com/@3protv"},
            {"name": "ì—°í•©ì¸í¬ë§¥ìŠ¤", "url": "https://news.einfomax.co.kr"}
        ]

        # 6. ë¦¬í¬íŠ¸ ì¡°ë¦½ (ìŠ¬ë™ìš© í…ìŠ¤íŠ¸ ë¦¬í¬íŠ¸)
        report = [
            f"ğŸ›¡ï¸ **[ì•ŒíŒŒ HQ] ì°¸ëª¨ì´ì¥ {cabin_info['name']} í†µí•© ì§€íœ˜ ë³´ê³  (Master Update)**",
            f"ë³´ê³ ì‹œê°: {datetime.now().strftime('%Y-%m-%d %H:%M')}\n",
            "**[ì§€íœ˜ê´€ ì „ëµ ì§€ì¹¨: ì„¸ë¶„í™”ëœ ì „ëµ ëŒ€ì‘]**",
            f"{experts_opinions[cabin_info['name']]}\n",
            "---",
            "### **Section A: ê¸€ë¡œë²Œ ë§¤í¬ë¡œ & ê²½ì œ ì „ë§**",
            f"**í•µì‹¬ í‚¤ì›Œë“œ 3:** {', '.join(keywords)}",
            f"\n[ì‹¤ì‹œê°„ í—¤ë“œë¼ì¸ ìš”ì•½]",
            "\n".join([f"- {h}" for h in headlines]),
            f"\n[ì§€í‘œ í˜„í™©]\n{macro_data_text}",
            
            "\n---",
            "### **Section B: ì˜¤ëŠ˜ì˜ íŠ¹ì§•ì£¼ & ì¶”ê°€ ê²€í†  ì œì•ˆ**",
        ]
        
        for stock in featured_stocks:
            report.append(f"â–¶ **{stock['name']}**")
            report.append(f"   - ê·¼ê±°: {stock['reason']}")
            report.append(f"   - **ì œì•ˆ: '{stock['comment']}'**")
            
        if recent_intel:
            report.append("\n---")
            report.append("### **Section D: í…”ë ˆê·¸ë¨ ì‹¤ì‹œê°„ ì •ë³´ (ì„¸ì‚¬ëª¨ Insight)**")
            for intel in recent_intel[-5:]:
                report.append(f"ğŸ’¬ [{intel['source']}] {intel['content'][:100]}...")

        report.append("\n---")
        report.append("### **Section C: ì½”ì–´ ì„¹í„° í€ë”ë©˜íƒˆ í˜„í™©**")
        report.append(latest_prices.to_string())
        
        report.append("\n" + "="*60)
        report.append("âš ï¸ íˆ¬ì ë¦¬ìŠ¤í¬: ë¦¬ìŠ¤í¬ ê´€ë¦¬ë¥¼ ìœ„í•´ í˜„ê¸ˆ 10% ë¹„ì¤‘ ìœ ì§€ëŠ” í•„ìˆ˜ì…ë‹ˆë‹¤.")
        report.append(f"= ì°¸ëª¨ì´ì¥ {cabin_info['name']} (Alpha HQ) ë°°ìƒ =")

        # [NEW] ëª¨ë¸ íš¨ìœ¨í™” ì •ë³´ ì¶”ê°€ (antigravitiyusingorder.md ë°˜ì˜)
        report.append("\n" + "-"*40)
        report.append("ğŸ“Š **Model & Intelligence Efficiency**")
        active_models = sorted(list(set(s.get("model") for s in self.staff.values() if s.get("model"))))
        report.append(f"â€¢ Active Models: {', '.join(active_models)}")
        report.append("â€¢ Analysis Pipeline: Hierarchical (Flash Scan -> Deep Analysis)")
        report.append("â€¢ Token Efficiency: ~75% Saved (Context Caching & Summary First)")
        
        final_report_text = "\n".join(report)
        print(final_report_text)
        
        # 7. ë…¸ì…˜ ì „ì†¡
        notion_data = {
            "title": f"ì°¸ëª¨ì§„ í†µí•© ì‹œì¥ ë¶„ì„ ë³´ê³  ({cabin_info['name']} ì§€íœ˜)",
            "experts": experts_opinions,
            "market_table": market_table,
            "links": reference_links
        }
        
        # KR/US êµ¬ë¶„ (ìƒ˜í”Œ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ê¸°ì¤€ìœ¼ë¡œ KR ì „ì†¡)
        self.notion.send_report('KR', notion_data)

        # 8. ê¸°ì¡´ ì±„ë„ ì•Œë¦¼ ë° íŒŒì¼ ì €ì¥
        self.send_to_slack(final_report_text, self.slack_channel_daily)

        try:
            from telegram_notifier import TelegramNotifier
            tel_config = self.config.get("telegram", {})
            telegram = TelegramNotifier(token=tel_config.get("token"), chat_id=tel_config.get("chat_id"))
            telegram.send_message(f"ğŸš¨ **[ì•ŒíŒŒ HQ ëª¨ë‹ ë¸Œë¦¬í•‘]**\n\n{final_report_text[:500]}...")
        except Exception as e:
            print(f"í…”ë ˆê·¸ë¨ ë°œì†¡ ì‹¤íŒ¨: {e}")

        if featured_stocks:
            print(f"[{datetime.now()}] [{park_info['name']}] íŠ¹ì§•ì£¼ {len(featured_stocks)}ì¢…ëª© ì„¼í‹°ë„ ê°ì‹œ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€ ì¤‘...")
            for stock in featured_stocks:
                self.manager.add_to_watchlist(stock['name'], 0)
        
        file_name = f"comprehensive_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        with open(os.path.join(self.report_dir, file_name), 'w', encoding='utf-8') as f:
            f.write(final_report_text)
        
        return final_report_text

    def send_to_slack(self, text, channel_id):
        url = "https://slack.com/api/chat.postMessage"
        headers = {"Authorization": f"Bearer {self.slack_token}", "Content-Type": "application/json"}
        try:
            response = requests.post(url, headers=headers, json={"channel": channel_id, "text": text}, timeout=10)
            res_data = response.json()
            if res_data.get("ok"):
                print(f"[ì„±ê³µ] ìŠ¬ë™ ë©”ì‹œì§€ ì „ì†¡ ì™„ë£Œ (ì±„ë„: {channel_id})")
            else:
                print(f"[ì‹¤íŒ¨] ìŠ¬ë™ ì „ì†¡ ì˜¤ë¥˜: {res_data.get('error')}")
        except Exception as e:
            print(f"[ì˜¤ë¥˜] ìŠ¬ë™ ì—°ë™ ì¤‘ ë¬¸ì œ ë°œìƒ: {e}")

if __name__ == "__main__":
    scanner = MarketScanner()
    scanner.run_comprehensive_scan()
